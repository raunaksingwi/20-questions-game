# =============================================================================
# 20 Questions Game - Environment Variables
# =============================================================================
# Copy this file to .env and fill in your actual values
# This file supports both local development and Supabase Edge Functions

# =============================================================================
# SUPABASE CONFIGURATION
# =============================================================================
SUPABASE_URL=your_supabase_project_url
SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================
# Choose the default LLM provider: 'anthropic' or 'openai'
LLM_PROVIDER=anthropic

# =============================================================================
# ANTHROPIC CONFIGURATION
# =============================================================================
# Required when using Anthropic (Claude) as LLM provider
ANTHROPIC_API_KEY=your_anthropic_api_key_here
# Optional: Override default model (default: claude-3-haiku-20240307)
ANTHROPIC_MODEL=claude-3-haiku-20240307

# =============================================================================
# OPENAI CONFIGURATION  
# =============================================================================
# Required when using OpenAI as LLM provider
OPENAI_API_KEY=your_openai_api_key_here
# Optional: Override default model (default: gpt-4o-mini)
OPENAI_MODEL=gpt-4o-mini
# Optional: Organization ID for OpenAI API
OPENAI_ORG_ID=your_openai_org_id
# Optional: Custom base URL for OpenAI-compatible APIs
OPENAI_BASE_URL=https://api.openai.com

# =============================================================================
# FUNCTION-SPECIFIC LLM OVERRIDES
# =============================================================================
# Override LLM provider for specific functions (optional)
# Format: <FUNCTION_NAME>_LLM_PROVIDER=provider_name

# Use different provider for asking questions
# ASK_QUESTION_LLM_PROVIDER=openai

# Use different provider for generating hints  
# GET_HINT_LLM_PROVIDER=anthropic

# =============================================================================
# MOBILE APP CONFIGURATION (app/.env)
# =============================================================================
# These should also be set in app/.env for the React Native app:
# EXPO_PUBLIC_SUPABASE_URL=your_supabase_project_url
# EXPO_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key

# =============================================================================
# DEPLOYMENT NOTES
# =============================================================================
# For Supabase Edge Functions deployment:
# 1. Set environment variables in Supabase Dashboard > Settings > Environment Variables
# 2. All variables listed above can be set there
# 3. The functions will automatically pick up these environment variables

# For local development:
# 1. Copy this file to .env in the project root
# 2. Fill in your actual API keys and configuration
# 3. Run: supabase start (to start local Supabase)
# 4. Run: supabase functions serve (to serve functions locally)