/**
 * Test script for validating the evaluation system functionality.
 * Runs sample evaluations to ensure all components work correctly.
 */

import { QuestioningEvaluator, CategoryQuestioningEvaluator } from './QuestioningEvaluator.ts'
import { GuessingEvaluator } from './GuessingEvaluator.ts'
import { HintEvaluator } from './HintEvaluator.ts'
import { GoldenTestSets } from './TestScenarios.ts'
import { EvaluationRunner } from './EvaluationRunner.ts'

/**
 * Runs a sample evaluation to test system functionality
 */
async function runSampleEvaluation(): Promise<void> {
  console.log('üß™ Testing Evaluation System...\n')

  // Test 1: Questioning Evaluator
  console.log('1Ô∏è‚É£ Testing Questioning Evaluator...')
  const questioningEvaluator = new CategoryQuestioningEvaluator('animals')
  const questioningScenarios = questioningEvaluator.createCategoryTestScenarios()
  
  if (questioningScenarios.length > 0) {
    const questioningResult = await questioningEvaluator.evaluateScenario(questioningScenarios[0])
    console.log(`   ‚úÖ Animals questioning evaluation: ${questioningResult.passed ? 'PASSED' : 'FAILED'} (Score: ${questioningResult.overallScore.toFixed(2)})`)
    console.log(`   üìä Metrics: ${questioningResult.metrics.length} collected`)
  }

  // Test 2: Guessing Evaluator
  console.log('\n2Ô∏è‚É£ Testing Guessing Evaluator...')
  const guessingEvaluator = new GuessingEvaluator()
  const guessingScenarios = GoldenTestSets.createGuessingGoldenTests()
  
  if (guessingScenarios.length > 0) {
    const guessingResult = await guessingEvaluator.evaluateScenario(guessingScenarios[0])
    console.log(`   ‚úÖ Guessing evaluation: ${guessingResult.passed ? 'PASSED' : 'FAILED'} (Score: ${guessingResult.overallScore.toFixed(2)})`)
    console.log(`   üìä Metrics: ${guessingResult.metrics.length} collected`)
  }

  // Test 3: Hint Evaluator
  console.log('\n3Ô∏è‚É£ Testing Hint Evaluator...')
  const hintEvaluator = new HintEvaluator()
  const hintScenarios = GoldenTestSets.createHintGoldenTests()
  
  if (hintScenarios.length > 0) {
    const hintResult = await hintEvaluator.evaluateScenario(hintScenarios[0])
    console.log(`   ‚úÖ Hint evaluation: ${hintResult.passed ? 'PASSED' : 'FAILED'} (Score: ${hintResult.overallScore.toFixed(2)})`)
    console.log(`   üìä Metrics: ${hintResult.metrics.length} collected`)
  }

  // Test 4: Evaluation Runner
  console.log('\n4Ô∏è‚É£ Testing Evaluation Runner...')
  const runner = new EvaluationRunner()
  const quickReport = await runner.runQuickEvaluation()
  
  console.log(`   ‚úÖ Quick evaluation completed: ${quickReport.overallMetrics.passedTests}/${quickReport.overallMetrics.totalTests} passed`)
  console.log(`   üìà Average score: ${quickReport.overallMetrics.averageScore.toFixed(2)}`)
  console.log(`   ‚è±Ô∏è Execution time: ${Math.round(quickReport.overallMetrics.executionTimeMs / 1000)}s`)
  
  if (quickReport.recommendations.length > 0) {
    console.log(`   üí° Recommendations: ${quickReport.recommendations.length} generated`)
  }

  console.log('\nüéâ Evaluation system test completed successfully!')
  
  // Show sample metrics breakdown
  console.log('\nüìã Sample Metrics Breakdown:')
  if (quickReport.suiteResults.length > 0 && quickReport.suiteResults[0].results.length > 0) {
    const sampleResult = quickReport.suiteResults[0].results[0]
    console.log(`   Test: ${sampleResult.testScenario}`)
    console.log(`   Evaluator: ${sampleResult.evaluatorName}`)
    console.log(`   Overall Score: ${sampleResult.overallScore}`)
    console.log(`   Metrics (${sampleResult.metrics.length} total):`)
    
    sampleResult.metrics.slice(0, 5).forEach(metric => {
      const status = metric.passed === true ? '‚úÖ' : metric.passed === false ? '‚ùå' : '‚è∏Ô∏è'
      console.log(`     ${status} ${metric.name}: ${metric.value.toFixed(2)} ${metric.threshold ? `(threshold: ${metric.threshold})` : ''}`)
    })
    
    if (sampleResult.metrics.length > 5) {
      console.log(`     ... and ${sampleResult.metrics.length - 5} more metrics`)
    }
  }
}

/**
 * Validates all evaluation components work correctly
 */
async function validateEvaluationComponents(): Promise<boolean> {
  console.log('üîç Validating Evaluation Components...\n')
  
  let allValid = true

  try {
    // Validate questioning evaluators for all categories
    const categories = ['animals', 'objects', 'world leaders', 'cricket players', 'football players', 'nba players']
    
    for (const category of categories) {
      const evaluator = new CategoryQuestioningEvaluator(category)
      const scenarios = evaluator.createCategoryTestScenarios()
      
      if (scenarios.length === 0) {
        console.log(`   ‚ùå ${category}: No test scenarios generated`)
        allValid = false
      } else {
        console.log(`   ‚úÖ ${category}: ${scenarios.length} test scenarios generated`)
      }
    }

    // Validate test scenario generation
    const goldenQuestioningTests = GoldenTestSets.createQuestioningGoldenTests()
    const goldenGuessingTests = GoldenTestSets.createGuessingGoldenTests()
    const goldenHintTests = GoldenTestSets.createHintGoldenTests()
    
    console.log(`   ‚úÖ Golden test sets: ${goldenQuestioningTests.length + goldenGuessingTests.length + goldenHintTests.length} scenarios`)

    // Validate benchmarks
    const benchmarks = GoldenTestSets.createPerformanceBenchmarks()
    const totalBenchmarks = benchmarks.questioning.length + benchmarks.guessing.length + benchmarks.hinting.length
    console.log(`   ‚úÖ Performance benchmarks: ${totalBenchmarks} scenarios`)

    // Validate adversarial tests
    const adversarial = GoldenTestSets.createAdversarialTests()
    const totalAdversarial = adversarial.questioning.length + adversarial.guessing.length + adversarial.hinting.length
    console.log(`   ‚úÖ Adversarial tests: ${totalAdversarial} scenarios`)

    console.log(`\n${allValid ? '‚úÖ' : '‚ùå'} Component validation ${allValid ? 'completed successfully' : 'failed'}`)
    
  } catch (error) {
    console.error('‚ùå Validation error:', error)
    allValid = false
  }

  return allValid
}

/**
 * Demonstrates evaluation output formats
 */
async function demonstrateOutputFormats(): Promise<void> {
  console.log('\nüìÑ Demonstration of Output Formats...\n')

  const runner = new EvaluationRunner()
  
  // Generate sample report
  const sampleReport = await runner.runQuickEvaluation()
  
  // Show JSON export
  console.log('üìã JSON Export Sample:')
  const jsonOutput = runner.exportResults(sampleReport)
  const truncatedJson = jsonOutput.substring(0, 500) + '...'
  console.log(truncatedJson)
  
  // Show category breakdown
  console.log('\nüìä Category Breakdown Sample:')
  for (const [category, data] of Object.entries(sampleReport.categoryBreakdown)) {
    console.log(`   ${category}:`)
    console.log(`     Pass Rate: ${data.passRate}%`)
    console.log(`     Average Score: ${data.averageScore}`)
    if (data.criticalFailures.length > 0) {
      console.log(`     Critical Failures: ${data.criticalFailures.length}`)
    }
  }
  
  // Show recommendations
  if (sampleReport.recommendations.length > 0) {
    console.log('\nüí° Recommendations Sample:')
    sampleReport.recommendations.slice(0, 3).forEach((rec, index) => {
      console.log(`   ${index + 1}. ${rec}`)
    })
  }
}

// Main execution
if (import.meta.main) {
  console.log('üöÄ 20 Questions Prompt Evaluation System Test\n')
  
  try {
    // Step 1: Validate components
    const isValid = await validateEvaluationComponents()
    
    if (isValid) {
      // Step 2: Run sample evaluation
      await runSampleEvaluation()
      
      // Step 3: Demonstrate output formats
      await demonstrateOutputFormats()
      
      console.log('\nüéØ All tests completed successfully!')
      console.log('\nüìö Next steps:')
      console.log('   ‚Ä¢ Run "deno run --allow-all EvaluationRunner.ts complete" for full evaluation')
      console.log('   ‚Ä¢ Integrate evaluation into your development workflow')
      console.log('   ‚Ä¢ Set up CI/CD automation for continuous monitoring')
      
    } else {
      console.log('\n‚ùå Component validation failed. Please check the implementation.')
      Deno.exit(1)
    }
    
  } catch (error) {
    console.error('\nüí• Test execution failed:', error)
    Deno.exit(1)
  }
}